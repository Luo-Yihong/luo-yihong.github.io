---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Short Bio
===
<!-- I obtained my Master's degree at the [HCP Lab](http://www.sysu-hcp.net/home/) and bachelor's degree in SYSU, where I was fortunately advised by [Prof. Xiaodan Liang](https://scholar.google.com/citations?user=voxznZAAAAAJ&hl=zh-CN) to conduct research in NLP. -->


<!-- Research Interests
=== -->
I’m Yihong Luo, currently pursuing a PhD with a keen focus on Deep Genearative Models and Graph Neural Networks. Under the guidance and collaboration of esteemed advisors: [Jing Tang](https://scholar.google.com/citations?hl=zh-CN&user=0S4cpyoAAAAJ). I focus on the following topics:
* Few-Step Text-to-Image/Video Diffusion Models
* Energy-Based Models
* Graph Neural Networks
  
> If you’re interested in collaborating or exploring potential research opportunities, please don’t hesitate to reach out (带带哥们). 


News
===
- **<font style = "color:#FF8000">[01/2025]</font>** Two papers accepted to ***ICLR 2025***.


Preprints
===
<strong><font style = "color:#1f57b8">OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling</font></strong><br />
<strong>Yihong Luo</strong>, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song, Xiaodan Liang, Jing Tang<br />
[[Paper]](https://arxiv.org/abs/2407.09887v3) [[Code]](https://github.com/yihongluo/ReSocratic) <br /> 


Selected Publication 
===
<strong><font style = "color:#1f57b8">AlignedCoT: Prompting Large Language Models via Native-Speaking Demonstrations</font></strong><br />
<strong>Yihong Luo</strong>, Yinya Huang, Jing Xiong, Liang Feng, Xiaodan Liang, Yiwei Wang, Jing Tang <br />
The 2024 Conference on Empirical Methods in Natural Language Processing. (Findings of EMNLP 2024) <br />
[[Paper]](https://aclanthology.org/2024.findings-emnlp.163/) [[Code]](https://github.com/yihongluo/AlignedCoT) <br /> 

<strong><font style = "color:#1f57b8">LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning</font></strong><br />
<strong>Yihong Luo<sup>*</sup></strong>, Jinghui Qin<sup>*</sup>, Jiaqi Chen, Liang Lin, Xiaodan Liang<br />
The 2022 Conference on Empirical Methods in Natural Language Processing. (Findings of EMNLP 2022) <br />
[[Paper]](https://anthology.aclweb.org/2022.findings-emnlp.1/) [[Code]](https://github.com/yihongluo/InterMWP)<br />

<strong><font style = "color:#1f57b8">Unbiased Math Word Problems Benchmark for Mitigating Solving Bias</font></strong><br />
<strong>Yihong Luo</strong>, Jinghui Qin, Jiaqi Chen, Xiaodan Liang<br />
Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2022. (Findings of NAACL 2022)<br />
[[Paper]](https://aclanthology.org/2022.findings-naacl.104/) [[Code]](https://github.com/yihongluo/UnbiasedMWP) <br />

<strong><font style = "color:#1f57b8">CLOMO: Counterfactual Logical Modification with Large Language Models</font></strong><br />
Yinya Huang, Ruixin Hong, Hongming Zhang, Wei Shao, <strong>Yihong Luo</strong>, Dong Yu, Changshui Zhang, Xiaodan Liang, Linqi Song <br />
Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. (ACL 2024) <br />
[[Paper]](https://arxiv.org/abs/2311.17438) <br />

<strong><font style = "color:#1f57b8">DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning</font></strong><br />
Jing Xiong, Zixuan Li, Chuanyang Zheng, Zhijiang Guo, Yichun Yin, Enze Xie, <strong>Yihong Luo</strong>, Qingxing Cao, Haiming Wang, Xiongwei Han, Jing Tang, Chengming Li, Xiaodan Liang <br />
12th International Conference on Learning Representations, 2024. (ICLR 2024)<br />
[[Paper]](https://arxiv.org/abs/2310.02954) <br />

<strong><font style = "color:#1f57b8">ATG: Benchmarking Automated Theorem Generation for Generative Language Models</font></strong><br />
Xiaohan Lin, Qingxing Cao, Yinya Huang, **Yihong Luo**, Zhengying Liu, Zhenguo Li, Xiaodan Liang <br />
Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2024. (Findings of NAACL 2024)<br />
[[Paper]](https://openreview.net/forum?id=H0RzzhAxTv&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FNAACL%2F2024%2FConference%2FAuthors%23your-submissions)) <br />

<strong><font style = "color:#1f57b8">Template-based Contrastive Distillation Pre-training for Math Word Problem Solving</font></strong><br />
Jinghui Qin*, <strong>Yihong Luo*</strong>, Jiaqi Chen, Xiaodan Liang and Liang Lin<br />
IEEE Transactions on Neural Networks and Learning Systems, 2023. (TNNLS) <br />
[[Paper]](https://ieeexplore.ieee.org/document/10113691) <br />

(* denotes co-first authors) <br />


Education
===
* 2020 --- 2023: **Master** in Pattern Recognition and Intelligent Systems, Sun Yat-sen University (Shenzhen)
* 2016 --- 2020: **B.Sc.** in Computer Science and Technology, Sun Yat-sen University (Panyu)


Honors and Awards
===
* National First Prize, Contemporary Undergraduate Mathematical Contest in Modeling (CUMCM), China
* First Prize Scholarship, Sun Yat-sen University

Experience
===
* <div>NLP Research Intern, Huawei Noah's Ark</div> 
* <div>Recommender System Intern, ByteDance-Data-Douyin</div> 
* <div>NLP Research Intern, DMAI</div> 

---
<script>
document.write("Last modifid at: "+document.lastModified+"" )
</script>

<a href="https://info.flagcounter.com/kdvh"><img src="https://s11.flagcounter.com/map/kdvh/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>
